{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"markdown","source":"# Logistic Regression with TF"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"## Import Libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport tensorflow as tf\n\ntf.random.set_seed(777)  # for reproducibility\nprint(tf.__version__)","execution_count":1,"outputs":[{"output_type":"stream","text":"2.2.0\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train = [[1., 2.],\n          [2., 3.],\n          [3., 1.],\n          [4., 3.],\n          [5., 3.],\n          [6., 2.]]\ny_train = [[0.],\n          [0.],\n          [0.],\n          [1.],\n          [1.],\n          [1.]]\n\nx_test = [[5.,2.]]\ny_test = [[1.]]\n\n\nx1 = [x[0] for x in x_train]\nx2 = [x[1] for x in x_train]\n\ncolors = [int(y[0] % 3) for y in y_train]\nplt.scatter(x1,x2, c=colors , marker='^')\nplt.scatter(x_test[0][0],x_test[0][1], c=\"red\")\n\nplt.xlabel(\"x1\")\nplt.ylabel(\"x2\")\nplt.show()","execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(len(x_train))#.repeat()","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"W = tf.Variable(tf.zeros([2,1]), name='weight')\nb = tf.Variable(tf.zeros([1]), name='bias')","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def logistic_regression(features):\n    hypothesis  = tf.divide(1., 1. + tf.exp(tf.matmul(features, W) + b))\n    return hypothesis","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def loss_fn(hypothesis, features, labels):\n    cost = -tf.reduce_mean(labels * tf.math.log(logistic_regression(features)) + (1 - labels) * tf.math.log(1 - hypothesis))\n    return cost\n\noptimizer = tf.keras.optimizers.SGD(learning_rate=0.01)","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def accuracy_fn(hypothesis, labels):\n    predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n    accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, labels), dtype=tf.int32))\n    return accuracy","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Calculate Gradient\n\ndef grad(features, labels):\n    with tf.GradientTape() as tape:\n        loss_value = loss_fn(logistic_regression(features),features,labels)\n    return tape.gradient(loss_value, [W,b])","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Start learning\n\nEPOCHS = 1001\n\nfor step in range(EPOCHS):\n    for features, labels  in iter(dataset):\n        grads = grad(features, labels)\n        optimizer.apply_gradients(grads_and_vars=zip(grads,[W,b]))\n        if step % 100 == 0:\n            print(\"Iter: {}, Loss: {:.4f}\".format(step, loss_fn(logistic_regression(features),features,labels)))\ntest_acc = accuracy_fn(logistic_regression(x_test),y_test)\nprint(\"Testset Accuracy: {:.4f}\".format(test_acc))","execution_count":12,"outputs":[{"output_type":"stream","text":"Iter: 0, Loss: 0.6874\nIter: 100, Loss: 0.5776\nIter: 200, Loss: 0.5349\nIter: 300, Loss: 0.5054\nIter: 400, Loss: 0.4838\nIter: 500, Loss: 0.4671\nIter: 600, Loss: 0.4535\nIter: 700, Loss: 0.4420\nIter: 800, Loss: 0.4319\nIter: 900, Loss: 0.4228\nIter: 1000, Loss: 0.4144\nTestset Accuracy: 1.0000\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## Full Example - Diabetes Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport tensorflow as tf\n\ntf.random.set_seed(777)  # for reproducibility\nprint(tf.__version__)","execution_count":13,"outputs":[{"output_type":"stream","text":"2.2.0\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"xy = np.loadtxt('../input/data-03-diabetes.csv', delimiter=',', dtype=np.float32)\nx_train = xy[:, 0:-1]\ny_train = xy[:, [-1]]\n\nprint(x_train.shape, y_train.shape)\nprint(xy)","execution_count":16,"outputs":[{"output_type":"stream","text":"(759, 8) (759, 1)\n[[-0.294118   0.487437   0.180328  ... -0.53117   -0.0333333  0.       ]\n [-0.882353  -0.145729   0.0819672 ... -0.766866  -0.666667   1.       ]\n [-0.0588235  0.839196   0.0491803 ... -0.492741  -0.633333   0.       ]\n ...\n [-0.411765   0.21608    0.180328  ... -0.857387  -0.7        1.       ]\n [-0.882353   0.266332  -0.0163934 ... -0.768574  -0.133333   0.       ]\n [-0.882353  -0.0653266  0.147541  ... -0.797609  -0.933333   1.       ]]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(len(x_train))","execution_count":17,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"W = tf.Variable(tf.random.normal((8, 1)), name='weight')\nb = tf.Variable(tf.random.normal((1,)), name='bias')","execution_count":18,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def logistic_regression(features):\n    hypothesis  = tf.divide(1., 1. + tf.exp(tf.matmul(features, W) + b))\n    return hypothesis","execution_count":19,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def loss_fn(hypothesis, features, labels):\n    cost = -tf.reduce_mean(labels * tf.math.log(logistic_regression(features)) + (1 - labels) * tf.math.log(1 - hypothesis))\n    return cost\n\noptimizer = tf.keras.optimizers.SGD(learning_rate=0.01)","execution_count":20,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def accuracy_fn(hypothesis, labels):\n    predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n    accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, labels), dtype=tf.int32))\n    return accuracy","execution_count":21,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def grad(hypothesis, features, labels):\n    with tf.GradientTape() as tape:\n        loss_value = loss_fn(logistic_regression(features),features,labels)\n    return tape.gradient(loss_value, [W,b])","execution_count":22,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"EPOCHS = 1001\n\nfor step in range(EPOCHS):\n    for features, labels  in iter(dataset):\n        grads = grad(logistic_regression(features), features, labels)\n        optimizer.apply_gradients(grads_and_vars=zip(grads,[W,b]))\n        if step % 100 == 0:\n            print(\"Iter: {}, Loss: {:.4f}\".format(step, loss_fn(logistic_regression(features),features,labels)))","execution_count":23,"outputs":[{"output_type":"stream","text":"Iter: 0, Loss: 0.6556\nIter: 100, Loss: 0.6188\nIter: 200, Loss: 0.5980\nIter: 300, Loss: 0.5854\nIter: 400, Loss: 0.5769\nIter: 500, Loss: 0.5704\nIter: 600, Loss: 0.5648\nIter: 700, Loss: 0.5599\nIter: 800, Loss: 0.5555\nIter: 900, Loss: 0.5513\nIter: 1000, Loss: 0.5475\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## Logistic Regression with tf.keras"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lab 5 Logistic Regression Classifier\nimport tensorflow as tf\n\nx_data = [[1, 2],\n          [2, 3],\n          [3, 1],\n          [4, 3],\n          [5, 3],\n          [6, 2]]\ny_data = [[0],\n          [0],\n          [0],\n          [1],\n          [1],\n          [1]]\n\ntf.model = tf.keras.Sequential()\ntf.model.add(tf.keras.layers.Dense(units=1, input_dim=2))\n\n# use sigmoid activation for 0~1 problem\ntf.model.add(tf.keras.layers.Activation('sigmoid'))\n\n''' \nbetter result with loss function == 'binary_crossentropy', try 'mse' for yourself\nadding accuracy metric to get accuracy report during training\n'''\ntf.model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.SGD(lr=0.01), metrics=['accuracy'])\ntf.model.summary()\n\nhistory = tf.model.fit(x_data, y_data, epochs=5000)\n\n# Accuracy report\nprint(\"Accuracy: \", history.history['accuracy'][-1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Logistic Regression Example with tf.keras - Diabetes Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lab 5 Logistic Regression Classifier\nimport tensorflow as tf\nimport numpy as np\n\nxy = np.loadtxt('../input/data-03-diabetes.csv', delimiter=',', dtype=np.float32)\nx_data = xy[:, 0:-1]\ny_data = xy[:, [-1]]\n\nprint(x_data.shape, y_data.shape)\n\ntf.model = tf.keras.Sequential()\n# multi-variable, x_data.shape[1] == feature counts == 8 in this case\ntf.model.add(tf.keras.layers.Dense(units=1, input_dim=x_data.shape[1], activation='sigmoid'))\ntf.model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.SGD(lr=0.01),  metrics=['accuracy'])\ntf.model.summary()\n\nhistory = tf.model.fit(x_data, y_data, epochs=500)\n\n# accuracy!\nprint(\"Accuracy: {0}\".format(history.history['accuracy'][-1]))\n\n# predict a single data point\ny_predict = tf.model.predict([[0.176471, 0.155779, 0, 0, 0, 0.052161, -0.952178, -0.733333]])\nprint(\"Predict: {0}\".format(y_predict))\n\n# evaluating model\nevaluate = tf.model.evaluate(x_data, y_data)\nprint(\"loss: {0}, accuracy: {1}\".format(evaluate[0], evaluate[1]))","execution_count":25,"outputs":[{"output_type":"stream","text":"(759, 8) (759, 1)\nModel: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense (Dense)                (None, 1)                 9         \n=================================================================\nTotal params: 9\nTrainable params: 9\nNon-trainable params: 0\n_________________________________________________________________\nEpoch 1/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.7309 - accuracy: 0.4269\nEpoch 2/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.7110 - accuracy: 0.4730\nEpoch 3/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.6950 - accuracy: 0.5415\nEpoch 4/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.6822 - accuracy: 0.5679\nEpoch 5/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.6717 - accuracy: 0.6087\nEpoch 6/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.6633 - accuracy: 0.6285\nEpoch 7/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.6562 - accuracy: 0.6364\nEpoch 8/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.6503 - accuracy: 0.6403\nEpoch 9/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.6453 - accuracy: 0.6416\nEpoch 10/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.6410 - accuracy: 0.6509\nEpoch 11/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.6372 - accuracy: 0.6509\nEpoch 12/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.6337 - accuracy: 0.6535\nEpoch 13/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.6307 - accuracy: 0.6561\nEpoch 14/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.6281 - accuracy: 0.6561\nEpoch 15/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.6255 - accuracy: 0.6574\nEpoch 16/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.6231 - accuracy: 0.6574\nEpoch 17/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.6209 - accuracy: 0.6614\nEpoch 18/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.6188 - accuracy: 0.6601\nEpoch 19/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.6168 - accuracy: 0.6614\nEpoch 20/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.6148 - accuracy: 0.6614\nEpoch 21/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.6130 - accuracy: 0.6614\nEpoch 22/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.6112 - accuracy: 0.6653\nEpoch 23/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.6094 - accuracy: 0.6653\nEpoch 24/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.6078 - accuracy: 0.6653\nEpoch 25/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.6061 - accuracy: 0.6653\nEpoch 26/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.6044 - accuracy: 0.6653\nEpoch 27/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.6028 - accuracy: 0.6653\nEpoch 28/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.6013 - accuracy: 0.6667\nEpoch 29/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5997 - accuracy: 0.6680\nEpoch 30/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5982 - accuracy: 0.6719\nEpoch 31/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5967 - accuracy: 0.6733\nEpoch 32/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5953 - accuracy: 0.6733\nEpoch 33/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5939 - accuracy: 0.6746\nEpoch 34/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5925 - accuracy: 0.6759\nEpoch 35/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5911 - accuracy: 0.6772\nEpoch 36/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5898 - accuracy: 0.6759\nEpoch 37/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5884 - accuracy: 0.6759\nEpoch 38/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5872 - accuracy: 0.6759\nEpoch 39/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5858 - accuracy: 0.6759\nEpoch 40/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5846 - accuracy: 0.6759\nEpoch 41/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5833 - accuracy: 0.6759\nEpoch 42/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5821 - accuracy: 0.6772\nEpoch 43/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5809 - accuracy: 0.6785\nEpoch 44/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5797 - accuracy: 0.6785\nEpoch 45/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5785 - accuracy: 0.6785\nEpoch 46/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5774 - accuracy: 0.6785\nEpoch 47/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5762 - accuracy: 0.6798\nEpoch 48/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5751 - accuracy: 0.6798\nEpoch 49/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5740 - accuracy: 0.6798\nEpoch 50/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5729 - accuracy: 0.6798\nEpoch 51/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5718 - accuracy: 0.6798\nEpoch 52/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5708 - accuracy: 0.6798\nEpoch 53/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5697 - accuracy: 0.6798\nEpoch 54/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5687 - accuracy: 0.6798\nEpoch 55/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5677 - accuracy: 0.6825\nEpoch 56/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5667 - accuracy: 0.6812\nEpoch 57/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5657 - accuracy: 0.6851\nEpoch 58/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5647 - accuracy: 0.6891\nEpoch 59/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5638 - accuracy: 0.6917\nEpoch 60/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5628 - accuracy: 0.6917\nEpoch 61/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5619 - accuracy: 0.6930\nEpoch 62/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5610 - accuracy: 0.6970\nEpoch 63/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5601 - accuracy: 0.6983\nEpoch 64/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5592 - accuracy: 0.7022\nEpoch 65/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5583 - accuracy: 0.7036\nEpoch 66/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5574 - accuracy: 0.7049\nEpoch 67/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5566 - accuracy: 0.7075\nEpoch 68/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5557 - accuracy: 0.7062\nEpoch 69/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5549 - accuracy: 0.7062\nEpoch 70/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5541 - accuracy: 0.7088\nEpoch 71/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5533 - accuracy: 0.7101\nEpoch 72/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5525 - accuracy: 0.7101\nEpoch 73/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5517 - accuracy: 0.7101\nEpoch 74/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5509 - accuracy: 0.7088\nEpoch 75/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5502 - accuracy: 0.7088\nEpoch 76/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5495 - accuracy: 0.7101\nEpoch 77/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5487 - accuracy: 0.7101\nEpoch 78/500\n","name":"stdout"},{"output_type":"stream","text":"24/24 [==============================] - 0s 1ms/step - loss: 0.5480 - accuracy: 0.7101\nEpoch 79/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5472 - accuracy: 0.7128\nEpoch 80/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5465 - accuracy: 0.7128\nEpoch 81/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5458 - accuracy: 0.7141\nEpoch 82/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5452 - accuracy: 0.7154\nEpoch 83/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5445 - accuracy: 0.7167\nEpoch 84/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5438 - accuracy: 0.7194\nEpoch 85/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5432 - accuracy: 0.7207\nEpoch 86/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5425 - accuracy: 0.7233\nEpoch 87/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5419 - accuracy: 0.7220\nEpoch 88/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5412 - accuracy: 0.7233\nEpoch 89/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5406 - accuracy: 0.7233\nEpoch 90/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5399 - accuracy: 0.7260\nEpoch 91/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5393 - accuracy: 0.7273\nEpoch 92/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5387 - accuracy: 0.7312\nEpoch 93/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5381 - accuracy: 0.7339\nEpoch 94/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5375 - accuracy: 0.7325\nEpoch 95/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5370 - accuracy: 0.7365\nEpoch 96/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5364 - accuracy: 0.7378\nEpoch 97/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5358 - accuracy: 0.7391\nEpoch 98/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5353 - accuracy: 0.7391\nEpoch 99/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5347 - accuracy: 0.7391\nEpoch 100/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5342 - accuracy: 0.7431\nEpoch 101/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5336 - accuracy: 0.7444\nEpoch 102/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5331 - accuracy: 0.7431\nEpoch 103/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5326 - accuracy: 0.7444\nEpoch 104/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5320 - accuracy: 0.7444\nEpoch 105/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5315 - accuracy: 0.7444\nEpoch 106/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5310 - accuracy: 0.7444\nEpoch 107/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5305 - accuracy: 0.7444\nEpoch 108/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5300 - accuracy: 0.7457\nEpoch 109/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5295 - accuracy: 0.7457\nEpoch 110/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5290 - accuracy: 0.7457\nEpoch 111/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5286 - accuracy: 0.7444\nEpoch 112/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5281 - accuracy: 0.7431\nEpoch 113/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5276 - accuracy: 0.7431\nEpoch 114/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5272 - accuracy: 0.7431\nEpoch 115/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5267 - accuracy: 0.7444\nEpoch 116/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5263 - accuracy: 0.7444\nEpoch 117/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5258 - accuracy: 0.7431\nEpoch 118/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5253 - accuracy: 0.7444\nEpoch 119/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5249 - accuracy: 0.7444\nEpoch 120/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5245 - accuracy: 0.7444\nEpoch 121/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5241 - accuracy: 0.7484\nEpoch 122/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5236 - accuracy: 0.7484\nEpoch 123/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5232 - accuracy: 0.7497\nEpoch 124/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5228 - accuracy: 0.7510\nEpoch 125/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5224 - accuracy: 0.7510\nEpoch 126/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5220 - accuracy: 0.7510\nEpoch 127/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5217 - accuracy: 0.7510\nEpoch 128/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5213 - accuracy: 0.7523\nEpoch 129/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5209 - accuracy: 0.7549\nEpoch 130/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5205 - accuracy: 0.7536\nEpoch 131/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5201 - accuracy: 0.7523\nEpoch 132/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5197 - accuracy: 0.7510\nEpoch 133/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5193 - accuracy: 0.7523\nEpoch 134/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5190 - accuracy: 0.7510\nEpoch 135/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5186 - accuracy: 0.7549\nEpoch 136/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5183 - accuracy: 0.7523\nEpoch 137/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5179 - accuracy: 0.7536\nEpoch 138/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5176 - accuracy: 0.7549\nEpoch 139/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5172 - accuracy: 0.7549\nEpoch 140/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5169 - accuracy: 0.7536\nEpoch 141/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5165 - accuracy: 0.7536\nEpoch 142/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5162 - accuracy: 0.7549\nEpoch 143/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5159 - accuracy: 0.7549\nEpoch 144/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5156 - accuracy: 0.7563\nEpoch 145/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5152 - accuracy: 0.7549\nEpoch 146/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5149 - accuracy: 0.7549\nEpoch 147/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5146 - accuracy: 0.7549\nEpoch 148/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5142 - accuracy: 0.7549\nEpoch 149/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5140 - accuracy: 0.7536\nEpoch 150/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5137 - accuracy: 0.7536\nEpoch 151/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5133 - accuracy: 0.7536\nEpoch 152/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5131 - accuracy: 0.7549\nEpoch 153/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5127 - accuracy: 0.7563\nEpoch 154/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5124 - accuracy: 0.7536\nEpoch 155/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5121 - accuracy: 0.7576\nEpoch 156/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5119 - accuracy: 0.7536\nEpoch 157/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5116 - accuracy: 0.7536\nEpoch 158/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5113 - accuracy: 0.7576\nEpoch 159/500\n","name":"stdout"},{"output_type":"stream","text":"24/24 [==============================] - 0s 1ms/step - loss: 0.5110 - accuracy: 0.7589\nEpoch 160/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5107 - accuracy: 0.7576\nEpoch 161/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5105 - accuracy: 0.7576\nEpoch 162/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5102 - accuracy: 0.7563\nEpoch 163/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5099 - accuracy: 0.7576\nEpoch 164/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5097 - accuracy: 0.7602\nEpoch 165/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5094 - accuracy: 0.7589\nEpoch 166/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5091 - accuracy: 0.7589\nEpoch 167/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5089 - accuracy: 0.7589\nEpoch 168/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5086 - accuracy: 0.7602\nEpoch 169/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5084 - accuracy: 0.7602\nEpoch 170/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5081 - accuracy: 0.7589\nEpoch 171/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5078 - accuracy: 0.7576\nEpoch 172/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5076 - accuracy: 0.7576\nEpoch 173/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5074 - accuracy: 0.7589\nEpoch 174/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5071 - accuracy: 0.7576\nEpoch 175/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5068 - accuracy: 0.7576\nEpoch 176/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5066 - accuracy: 0.7602\nEpoch 177/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5064 - accuracy: 0.7602\nEpoch 178/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5062 - accuracy: 0.7602\nEpoch 179/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5059 - accuracy: 0.7615\nEpoch 180/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5057 - accuracy: 0.7602\nEpoch 181/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5055 - accuracy: 0.7615\nEpoch 182/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5053 - accuracy: 0.7615\nEpoch 183/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5051 - accuracy: 0.7615\nEpoch 184/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5048 - accuracy: 0.7628\nEpoch 185/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5046 - accuracy: 0.7615\nEpoch 186/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5044 - accuracy: 0.7615\nEpoch 187/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5042 - accuracy: 0.7615\nEpoch 188/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5039 - accuracy: 0.7628\nEpoch 189/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5038 - accuracy: 0.7628\nEpoch 190/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5036 - accuracy: 0.7628\nEpoch 191/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5033 - accuracy: 0.7628\nEpoch 192/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5031 - accuracy: 0.7628\nEpoch 193/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5029 - accuracy: 0.7628\nEpoch 194/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5027 - accuracy: 0.7642\nEpoch 195/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5025 - accuracy: 0.7642\nEpoch 196/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5023 - accuracy: 0.7642\nEpoch 197/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5021 - accuracy: 0.7668\nEpoch 198/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5019 - accuracy: 0.7655\nEpoch 199/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5017 - accuracy: 0.7668\nEpoch 200/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5015 - accuracy: 0.7655\nEpoch 201/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5013 - accuracy: 0.7668\nEpoch 202/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5012 - accuracy: 0.7655\nEpoch 203/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5010 - accuracy: 0.7655\nEpoch 204/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5008 - accuracy: 0.7642\nEpoch 205/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5007 - accuracy: 0.7655\nEpoch 206/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5004 - accuracy: 0.7655\nEpoch 207/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5003 - accuracy: 0.7655\nEpoch 208/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.5001 - accuracy: 0.7655\nEpoch 209/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4999 - accuracy: 0.7655\nEpoch 210/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4997 - accuracy: 0.7655\nEpoch 211/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4996 - accuracy: 0.7668\nEpoch 212/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4994 - accuracy: 0.7668\nEpoch 213/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4992 - accuracy: 0.7668\nEpoch 214/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4991 - accuracy: 0.7668\nEpoch 215/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4989 - accuracy: 0.7668\nEpoch 216/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4988 - accuracy: 0.7668\nEpoch 217/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4986 - accuracy: 0.7668\nEpoch 218/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4984 - accuracy: 0.7668\nEpoch 219/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4982 - accuracy: 0.7668\nEpoch 220/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4981 - accuracy: 0.7668\nEpoch 221/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4979 - accuracy: 0.7668\nEpoch 222/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4978 - accuracy: 0.7668\nEpoch 223/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4976 - accuracy: 0.7681\nEpoch 224/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4975 - accuracy: 0.7681\nEpoch 225/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4973 - accuracy: 0.7694\nEpoch 226/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4972 - accuracy: 0.7694\nEpoch 227/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4970 - accuracy: 0.7694\nEpoch 228/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4969 - accuracy: 0.7681\nEpoch 229/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4967 - accuracy: 0.7694\nEpoch 230/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4966 - accuracy: 0.7694\nEpoch 231/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4964 - accuracy: 0.7694\nEpoch 232/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4963 - accuracy: 0.7708\nEpoch 233/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4961 - accuracy: 0.7708\nEpoch 234/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4960 - accuracy: 0.7708\nEpoch 235/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4958 - accuracy: 0.7708\nEpoch 236/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4957 - accuracy: 0.7708\nEpoch 237/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4956 - accuracy: 0.7708\nEpoch 238/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4954 - accuracy: 0.7694\nEpoch 239/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4953 - accuracy: 0.7694\nEpoch 240/500\n","name":"stdout"},{"output_type":"stream","text":"24/24 [==============================] - 0s 1ms/step - loss: 0.4952 - accuracy: 0.7694\nEpoch 241/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4951 - accuracy: 0.7708\nEpoch 242/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4949 - accuracy: 0.7708\nEpoch 243/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4948 - accuracy: 0.7694\nEpoch 244/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4947 - accuracy: 0.7708\nEpoch 245/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4945 - accuracy: 0.7708\nEpoch 246/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4944 - accuracy: 0.7708\nEpoch 247/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4943 - accuracy: 0.7708\nEpoch 248/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4941 - accuracy: 0.7708\nEpoch 249/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4940 - accuracy: 0.7708\nEpoch 250/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4939 - accuracy: 0.7708\nEpoch 251/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4937 - accuracy: 0.7708\nEpoch 252/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4936 - accuracy: 0.7708\nEpoch 253/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4935 - accuracy: 0.7708\nEpoch 254/500\n24/24 [==============================] - ETA: 0s - loss: 0.4251 - accuracy: 0.78 - 0s 1ms/step - loss: 0.4934 - accuracy: 0.7708\nEpoch 255/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4933 - accuracy: 0.7708\nEpoch 256/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4931 - accuracy: 0.7708\nEpoch 257/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4930 - accuracy: 0.7694\nEpoch 258/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4929 - accuracy: 0.7708\nEpoch 259/500\n24/24 [==============================] - ETA: 0s - loss: 0.3982 - accuracy: 0.87 - 0s 1ms/step - loss: 0.4928 - accuracy: 0.7694\nEpoch 260/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4927 - accuracy: 0.7694\nEpoch 261/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4925 - accuracy: 0.7708\nEpoch 262/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4925 - accuracy: 0.7708\nEpoch 263/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4923 - accuracy: 0.7708\nEpoch 264/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4922 - accuracy: 0.7694\nEpoch 265/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4921 - accuracy: 0.7694\nEpoch 266/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4920 - accuracy: 0.7694\nEpoch 267/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4919 - accuracy: 0.7694\nEpoch 268/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4918 - accuracy: 0.7694\nEpoch 269/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4917 - accuracy: 0.7694\nEpoch 270/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4916 - accuracy: 0.7694\nEpoch 271/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4915 - accuracy: 0.7694\nEpoch 272/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4914 - accuracy: 0.7694\nEpoch 273/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4913 - accuracy: 0.7694\nEpoch 274/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4911 - accuracy: 0.7694\nEpoch 275/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4910 - accuracy: 0.7694\nEpoch 276/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4910 - accuracy: 0.7694\nEpoch 277/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4909 - accuracy: 0.7694\nEpoch 278/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4907 - accuracy: 0.7694\nEpoch 279/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4906 - accuracy: 0.7694\nEpoch 280/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4905 - accuracy: 0.7694\nEpoch 281/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4904 - accuracy: 0.7694\nEpoch 282/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4904 - accuracy: 0.7694\nEpoch 283/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4903 - accuracy: 0.7694\nEpoch 284/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4901 - accuracy: 0.7694\nEpoch 285/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4901 - accuracy: 0.7681\nEpoch 286/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4900 - accuracy: 0.7694\nEpoch 287/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4899 - accuracy: 0.7681\nEpoch 288/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4898 - accuracy: 0.7694\nEpoch 289/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4897 - accuracy: 0.7681\nEpoch 290/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4896 - accuracy: 0.7681\nEpoch 291/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4895 - accuracy: 0.7668\nEpoch 292/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4894 - accuracy: 0.7655\nEpoch 293/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4893 - accuracy: 0.7668\nEpoch 294/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4892 - accuracy: 0.7681\nEpoch 295/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4891 - accuracy: 0.7668\nEpoch 296/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4891 - accuracy: 0.7668\nEpoch 297/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4890 - accuracy: 0.7655\nEpoch 298/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4889 - accuracy: 0.7668\nEpoch 299/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4888 - accuracy: 0.7681\nEpoch 300/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4887 - accuracy: 0.7655\nEpoch 301/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4886 - accuracy: 0.7681\nEpoch 302/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4885 - accuracy: 0.7655\nEpoch 303/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4884 - accuracy: 0.7655\nEpoch 304/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4883 - accuracy: 0.7655\nEpoch 305/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4883 - accuracy: 0.7655\nEpoch 306/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4882 - accuracy: 0.7655\nEpoch 307/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4881 - accuracy: 0.7655\nEpoch 308/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4880 - accuracy: 0.7655\nEpoch 309/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4879 - accuracy: 0.7655\nEpoch 310/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4879 - accuracy: 0.7655\nEpoch 311/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4878 - accuracy: 0.7655\nEpoch 312/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4877 - accuracy: 0.7655\nEpoch 313/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4876 - accuracy: 0.7655\nEpoch 314/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4876 - accuracy: 0.7655\nEpoch 315/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4875 - accuracy: 0.7655\nEpoch 316/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4874 - accuracy: 0.7655\nEpoch 317/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4873 - accuracy: 0.7655\nEpoch 318/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4872 - accuracy: 0.7655\nEpoch 319/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4872 - accuracy: 0.7655\nEpoch 320/500\n","name":"stdout"},{"output_type":"stream","text":"24/24 [==============================] - 0s 1ms/step - loss: 0.4871 - accuracy: 0.7655\nEpoch 321/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4870 - accuracy: 0.7655\nEpoch 322/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4869 - accuracy: 0.7655\nEpoch 323/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4869 - accuracy: 0.7655\nEpoch 324/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4868 - accuracy: 0.7668\nEpoch 325/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4867 - accuracy: 0.7655\nEpoch 326/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4867 - accuracy: 0.7655\nEpoch 327/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4866 - accuracy: 0.7655\nEpoch 328/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4865 - accuracy: 0.7655\nEpoch 329/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4864 - accuracy: 0.7668\nEpoch 330/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4864 - accuracy: 0.7668\nEpoch 331/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4863 - accuracy: 0.7668\nEpoch 332/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4862 - accuracy: 0.7668\nEpoch 333/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4862 - accuracy: 0.7668\nEpoch 334/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4861 - accuracy: 0.7668\nEpoch 335/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4860 - accuracy: 0.7668\nEpoch 336/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4860 - accuracy: 0.7668\nEpoch 337/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4859 - accuracy: 0.7668\nEpoch 338/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4858 - accuracy: 0.7655\nEpoch 339/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4858 - accuracy: 0.7668\nEpoch 340/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4857 - accuracy: 0.7655\nEpoch 341/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4856 - accuracy: 0.7655\nEpoch 342/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4856 - accuracy: 0.7655\nEpoch 343/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4855 - accuracy: 0.7642\nEpoch 344/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4854 - accuracy: 0.7655\nEpoch 345/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4854 - accuracy: 0.7655\nEpoch 346/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4853 - accuracy: 0.7655\nEpoch 347/500\n24/24 [==============================] - ETA: 0s - loss: 0.4963 - accuracy: 0.78 - 0s 1ms/step - loss: 0.4853 - accuracy: 0.7655\nEpoch 348/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4852 - accuracy: 0.7655\nEpoch 349/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4851 - accuracy: 0.7642\nEpoch 350/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4850 - accuracy: 0.7655\nEpoch 351/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4850 - accuracy: 0.7642\nEpoch 352/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4849 - accuracy: 0.7642\nEpoch 353/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4849 - accuracy: 0.7655\nEpoch 354/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4848 - accuracy: 0.7655\nEpoch 355/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4847 - accuracy: 0.7642\nEpoch 356/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4847 - accuracy: 0.7628\nEpoch 357/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4846 - accuracy: 0.7655\nEpoch 358/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4846 - accuracy: 0.7628\nEpoch 359/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4845 - accuracy: 0.7642\nEpoch 360/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4845 - accuracy: 0.7642\nEpoch 361/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4844 - accuracy: 0.7628\nEpoch 362/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4843 - accuracy: 0.7628\nEpoch 363/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4843 - accuracy: 0.7615\nEpoch 364/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4842 - accuracy: 0.7628\nEpoch 365/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4842 - accuracy: 0.7628\nEpoch 366/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4841 - accuracy: 0.7628\nEpoch 367/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4841 - accuracy: 0.7642\nEpoch 368/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4840 - accuracy: 0.7628\nEpoch 369/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4840 - accuracy: 0.7628\nEpoch 370/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4839 - accuracy: 0.7628\nEpoch 371/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4839 - accuracy: 0.7628\nEpoch 372/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4838 - accuracy: 0.7628\nEpoch 373/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4837 - accuracy: 0.7642\nEpoch 374/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4837 - accuracy: 0.7628\nEpoch 375/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4836 - accuracy: 0.7628\nEpoch 376/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4836 - accuracy: 0.7628\nEpoch 377/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4835 - accuracy: 0.7628\nEpoch 378/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4835 - accuracy: 0.7628\nEpoch 379/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4835 - accuracy: 0.7628\nEpoch 380/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4834 - accuracy: 0.7615\nEpoch 381/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4833 - accuracy: 0.7628\nEpoch 382/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4833 - accuracy: 0.7628\nEpoch 383/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4832 - accuracy: 0.7628\nEpoch 384/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4832 - accuracy: 0.7628\nEpoch 385/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4832 - accuracy: 0.7628\nEpoch 386/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4831 - accuracy: 0.7628\nEpoch 387/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4830 - accuracy: 0.7628\nEpoch 388/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4830 - accuracy: 0.7628\nEpoch 389/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4829 - accuracy: 0.7628\nEpoch 390/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4829 - accuracy: 0.7628\nEpoch 391/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4828 - accuracy: 0.7642\nEpoch 392/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4828 - accuracy: 0.7628\nEpoch 393/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4827 - accuracy: 0.7628\nEpoch 394/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4827 - accuracy: 0.7628\nEpoch 395/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4827 - accuracy: 0.7628\nEpoch 396/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4826 - accuracy: 0.7628\nEpoch 397/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4826 - accuracy: 0.7628\nEpoch 398/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4825 - accuracy: 0.7628\nEpoch 399/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4825 - accuracy: 0.7628\nEpoch 400/500\n","name":"stdout"},{"output_type":"stream","text":"24/24 [==============================] - 0s 1ms/step - loss: 0.4824 - accuracy: 0.7628\nEpoch 401/500\n24/24 [==============================] - ETA: 0s - loss: 0.5295 - accuracy: 0.71 - 0s 1ms/step - loss: 0.4824 - accuracy: 0.7628\nEpoch 402/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4824 - accuracy: 0.7628\nEpoch 403/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4823 - accuracy: 0.7628\nEpoch 404/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4822 - accuracy: 0.7628\nEpoch 405/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4822 - accuracy: 0.7628\nEpoch 406/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4821 - accuracy: 0.7628\nEpoch 407/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4821 - accuracy: 0.7628\nEpoch 408/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4821 - accuracy: 0.7628\nEpoch 409/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4820 - accuracy: 0.7628\nEpoch 410/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4820 - accuracy: 0.7628\nEpoch 411/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4819 - accuracy: 0.7642\nEpoch 412/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4819 - accuracy: 0.7642\nEpoch 413/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4818 - accuracy: 0.7628\nEpoch 414/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4818 - accuracy: 0.7628\nEpoch 415/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4818 - accuracy: 0.7642\nEpoch 416/500\n24/24 [==============================] - ETA: 0s - loss: 0.5066 - accuracy: 0.71 - 0s 1ms/step - loss: 0.4817 - accuracy: 0.7642\nEpoch 417/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4817 - accuracy: 0.7628\nEpoch 418/500\n24/24 [==============================] - ETA: 0s - loss: 0.4476 - accuracy: 0.84 - 0s 1ms/step - loss: 0.4817 - accuracy: 0.7642\nEpoch 419/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4816 - accuracy: 0.7642\nEpoch 420/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4816 - accuracy: 0.7655\nEpoch 421/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4815 - accuracy: 0.7642\nEpoch 422/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4815 - accuracy: 0.7642\nEpoch 423/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4814 - accuracy: 0.7668\nEpoch 424/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4814 - accuracy: 0.7668\nEpoch 425/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4814 - accuracy: 0.7655\nEpoch 426/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4813 - accuracy: 0.7655\nEpoch 427/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4813 - accuracy: 0.7668\nEpoch 428/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4812 - accuracy: 0.7668\nEpoch 429/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4812 - accuracy: 0.7668\nEpoch 430/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4812 - accuracy: 0.7642\nEpoch 431/500\n24/24 [==============================] - ETA: 0s - loss: 0.4281 - accuracy: 0.84 - 0s 1ms/step - loss: 0.4811 - accuracy: 0.7681\nEpoch 432/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4811 - accuracy: 0.7681\nEpoch 433/500\n24/24 [==============================] - ETA: 0s - loss: 0.4906 - accuracy: 0.78 - 0s 1ms/step - loss: 0.4811 - accuracy: 0.7668\nEpoch 434/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4810 - accuracy: 0.7681\nEpoch 435/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4810 - accuracy: 0.7681\nEpoch 436/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4809 - accuracy: 0.7681\nEpoch 437/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4809 - accuracy: 0.7681\nEpoch 438/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4809 - accuracy: 0.7681\nEpoch 439/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4808 - accuracy: 0.7681\nEpoch 440/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4808 - accuracy: 0.7681\nEpoch 441/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4808 - accuracy: 0.7681\nEpoch 442/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4807 - accuracy: 0.7681\nEpoch 443/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4807 - accuracy: 0.7681\nEpoch 444/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4807 - accuracy: 0.7681\nEpoch 445/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4806 - accuracy: 0.7681\nEpoch 446/500\n24/24 [==============================] - ETA: 0s - loss: 0.6020 - accuracy: 0.62 - 0s 1ms/step - loss: 0.4806 - accuracy: 0.7681\nEpoch 447/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4805 - accuracy: 0.7681\nEpoch 448/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4805 - accuracy: 0.7681\nEpoch 449/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4805 - accuracy: 0.7681\nEpoch 450/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4804 - accuracy: 0.7681\nEpoch 451/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4804 - accuracy: 0.7681\nEpoch 452/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4804 - accuracy: 0.7681\nEpoch 453/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4803 - accuracy: 0.7681\nEpoch 454/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4803 - accuracy: 0.7681\nEpoch 455/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4803 - accuracy: 0.7681\nEpoch 456/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4802 - accuracy: 0.7681\nEpoch 457/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4802 - accuracy: 0.7681\nEpoch 458/500\n24/24 [==============================] - ETA: 0s - loss: 0.5284 - accuracy: 0.78 - 0s 1ms/step - loss: 0.4802 - accuracy: 0.7681\nEpoch 459/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4802 - accuracy: 0.7681\nEpoch 460/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4801 - accuracy: 0.7681\nEpoch 461/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4801 - accuracy: 0.7681\nEpoch 462/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4800 - accuracy: 0.7681\nEpoch 463/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4800 - accuracy: 0.7681\nEpoch 464/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4800 - accuracy: 0.7681\nEpoch 465/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4799 - accuracy: 0.7681\nEpoch 466/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4800 - accuracy: 0.7681\nEpoch 467/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4799 - accuracy: 0.7681\nEpoch 468/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4799 - accuracy: 0.7681\nEpoch 469/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4798 - accuracy: 0.7681\nEpoch 470/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4798 - accuracy: 0.7681\nEpoch 471/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4797 - accuracy: 0.7681\nEpoch 472/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4797 - accuracy: 0.7681\nEpoch 473/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4797 - accuracy: 0.7681\nEpoch 474/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4797 - accuracy: 0.7681\nEpoch 475/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4797 - accuracy: 0.7681\nEpoch 476/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4796 - accuracy: 0.7681\nEpoch 477/500\n24/24 [==============================] - ETA: 0s - loss: 0.4837 - accuracy: 0.75 - 0s 1ms/step - loss: 0.4796 - accuracy: 0.7681\n","name":"stdout"},{"output_type":"stream","text":"Epoch 478/500\n24/24 [==============================] - ETA: 0s - loss: 0.5429 - accuracy: 0.68 - 0s 1ms/step - loss: 0.4796 - accuracy: 0.7681\nEpoch 479/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4796 - accuracy: 0.7694\nEpoch 480/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4795 - accuracy: 0.7681\nEpoch 481/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4795 - accuracy: 0.7681\nEpoch 482/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4794 - accuracy: 0.7694\nEpoch 483/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4794 - accuracy: 0.7694\nEpoch 484/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4794 - accuracy: 0.7694\nEpoch 485/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4794 - accuracy: 0.7694\nEpoch 486/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4793 - accuracy: 0.7694\nEpoch 487/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4793 - accuracy: 0.7694\nEpoch 488/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4793 - accuracy: 0.7694\nEpoch 489/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4792 - accuracy: 0.7694\nEpoch 490/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4792 - accuracy: 0.7694\nEpoch 491/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4792 - accuracy: 0.7694\nEpoch 492/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4792 - accuracy: 0.7694\nEpoch 493/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4792 - accuracy: 0.7694\nEpoch 494/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4791 - accuracy: 0.7694\nEpoch 495/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4791 - accuracy: 0.7694\nEpoch 496/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4791 - accuracy: 0.7694\nEpoch 497/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4790 - accuracy: 0.7694\nEpoch 498/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4790 - accuracy: 0.7694\nEpoch 499/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4790 - accuracy: 0.7694\nEpoch 500/500\n24/24 [==============================] - 0s 1ms/step - loss: 0.4790 - accuracy: 0.7694\nAccuracy: 0.7694334387779236\nPredict: [[0.61144197]]\n24/24 [==============================] - 0s 1ms/step - loss: 0.4789 - accuracy: 0.7694\nloss: 0.4788731038570404, accuracy: 0.7694334387779236\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}