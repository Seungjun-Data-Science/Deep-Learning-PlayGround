{"cells":[{"metadata":{},"cell_type":"markdown","source":"### **Downloading the Dataset**"},{"metadata":{},"cell_type":"markdown","source":"#### ML-100K"},{"metadata":{"trusted":true},"cell_type":"code","source":"  !wget \"http://files.grouplens.org/datasets/movielens/ml-100k.zip\"\n  !unzip ml-100k.zip\n  !ls","execution_count":1,"outputs":[{"output_type":"stream","text":"--2021-01-24 01:58:55--  http://files.grouplens.org/datasets/movielens/ml-100k.zip\nResolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\nConnecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:80... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 4924029 (4.7M) [application/zip]\nSaving to: ‘ml-100k.zip’\n\nml-100k.zip         100%[===================>]   4.70M  16.3MB/s    in 0.3s    \n\n2021-01-24 01:58:56 (16.3 MB/s) - ‘ml-100k.zip’ saved [4924029/4924029]\n\nArchive:  ml-100k.zip\n   creating: ml-100k/\n  inflating: ml-100k/allbut.pl       \n  inflating: ml-100k/mku.sh          \n  inflating: ml-100k/README          \n  inflating: ml-100k/u.data          \n  inflating: ml-100k/u.genre         \n  inflating: ml-100k/u.info          \n  inflating: ml-100k/u.item          \n  inflating: ml-100k/u.occupation    \n  inflating: ml-100k/u.user          \n  inflating: ml-100k/u1.base         \n  inflating: ml-100k/u1.test         \n  inflating: ml-100k/u2.base         \n  inflating: ml-100k/u2.test         \n  inflating: ml-100k/u3.base         \n  inflating: ml-100k/u3.test         \n  inflating: ml-100k/u4.base         \n  inflating: ml-100k/u4.test         \n  inflating: ml-100k/u5.base         \n  inflating: ml-100k/u5.test         \n  inflating: ml-100k/ua.base         \n  inflating: ml-100k/ua.test         \n  inflating: ml-100k/ub.base         \n  inflating: ml-100k/ub.test         \n__notebook_source__.ipynb  ml-100k  ml-100k.zip\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"#### ML-1M"},{"metadata":{"trusted":true},"cell_type":"code","source":"!wget \"http://files.grouplens.org/datasets/movielens/ml-1m.zip\"\n!unzip ml-1m.zip\n!ls","execution_count":2,"outputs":[{"output_type":"stream","text":"--2021-01-24 01:59:32--  http://files.grouplens.org/datasets/movielens/ml-1m.zip\nResolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\nConnecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:80... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 5917549 (5.6M) [application/zip]\nSaving to: ‘ml-1m.zip’\n\nml-1m.zip           100%[===================>]   5.64M  19.1MB/s    in 0.3s    \n\n2021-01-24 01:59:32 (19.1 MB/s) - ‘ml-1m.zip’ saved [5917549/5917549]\n\nArchive:  ml-1m.zip\n   creating: ml-1m/\n  inflating: ml-1m/movies.dat        \n  inflating: ml-1m/ratings.dat       \n  inflating: ml-1m/README            \n  inflating: ml-1m/users.dat         \n__notebook_source__.ipynb  ml-100k  ml-100k.zip  ml-1m\tml-1m.zip\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"### **Importing Libraries**"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.nn.parallel\nimport torch.optim as optim\nimport torch.utils.data\nfrom torch.autograd import Variable","execution_count":3,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Importing Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"# We won't be using this dataset.\nmovies = pd.read_csv('ml-1m/movies.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')\nusers = pd.read_csv('ml-1m/users.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')\nratings = pd.read_csv('ml-1m/ratings.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')","execution_count":4,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Preparing the training set and test set"},{"metadata":{"trusted":true},"cell_type":"code","source":"# In this dataset folder, there are 5 different train-test set pairs for k-fold cv // xx.base is the training set and xx.test is the test set\n# But we are just using one train-test set pair\n\ntraining_set = pd.read_csv('ml-100k/u1.base', delimiter = '\\t')\ntraining_set = np.array(training_set, dtype = 'int') #pytorch can also work with arrays so transfer data to numpy array\n\ntest_set = pd.read_csv('ml-100k/u1.test', delimiter = '\\t')\ntest_set = np.array(test_set, dtype = 'int') #pytorch can also work with arrays so transfer data to numpy array","execution_count":5,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Getting the number of users and movies"},{"metadata":{"trusted":true},"cell_type":"code","source":"# The maximum user_id or movie_id can be either in training_set or test_set so have to do max using both\n\nnb_users = int(max(max(training_set[:, 0]), max(test_set[:, 0]))) # index0 col = 1st column = user_id column\nnb_movies = int(max(max(training_set[:, 1]), max(test_set[:, 1]))) # index1 col = 2nd column = movid_id column","execution_count":8,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Converting the data into an array with \"users in lines\" and \"movies in columns\""},{"metadata":{"trusted":true},"cell_type":"code","source":"# For recommendation system, we need to struture the data in a particular manner\n# each movie has to correspond to each column/variable and each observation/line corresponds to each user(1st line = user1, 2nd line = user 2 ....)\n\n# Creating list of lists = what torch expects\ndef convert(data):\n    new_data = []\n    for id_users in range(1, nb_users + 1):\n        id_movies = data[:, 1] [data[:, 0] == id_users] # all the movie IDs each user watched\n        id_ratings = data[:, 2] [data[:, 0] == id_users] # all the ratings associated with those movies in the previous line\n        ratings = np.zeros(nb_movies)\n        ratings[id_movies - 1] = id_ratings\n        new_data.append(list(ratings))\n    return new_data\n\ntraining_set = convert(training_set)\ntest_set = convert(test_set)","execution_count":11,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Converting the data into Torch Tensors"},{"metadata":{"trusted":true},"cell_type":"code","source":"# torch = multi dimensional matrix which is way more efficient than numpy arrays for most deep learning operations\n\ntraining_set = torch.FloatTensor(training_set)\ntest_set = torch.FloatTensor(test_set)","execution_count":12,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Converting the ratings into binary ratings (1 liked) or 0 (not liked)"},{"metadata":{"trusted":true},"cell_type":"code","source":"training_set[training_set == 0] = -1\ntraining_set[training_set == 1] = 0\ntraining_set[training_set == 2] = 0\ntraining_set[training_set >= 3] = 1\n\ntest_set[test_set == 0] = -1\ntest_set[test_set == 1] = 0\ntest_set[test_set == 2] = 0\ntest_set[test_set >= 3] = 1","execution_count":15,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Creating Architecture of NN"},{"metadata":{"trusted":true},"cell_type":"code","source":"class RBM():\n    \n    ## Initializing Weights\n    def __init__(self, nv, nh): #nv: number of visible nodes ; nh: number of hidden nodes\n        self.W = torch.randn(nh, nv) # Returns a tensor filled with random numbers from a standard normal distribution(mean 0 and variance 1) with shape=(nh,nv)\n        self.a = torch.randn(1, nh) # \"1\" is intentional to maintain 2 dimensions ( as opposed to just .randn(nh) )\n        self.b = torch.randn(1, nv)\n        \n    def sample_h(self, x): # b=Wx+a; a: bias of hidden nodes; b: bias of visible nodes\n        wx = torch.mm(x, self.W.t()) #torch.mm : product of two tensors; t(): transpose\n        activation = wx + self.a.expand_as(wx) #.expand_as : expand dimension; bias is applied to each line of the mini batch\n        p_h_given_v = torch.sigmoid(activation) # p(h|v) = sigmoid activation function ==> applied to Wx+a\n        return p_h_given_v, torch.bernoulli(p_h_given_v) #bernoulli because it's binary problem(like or dislike movie) \n        #random sampling between 0~1 bernoulli distribution and if that number is below p_v_given_h, activate neuron(1s), not activate(0s) neuron otherwise\n    \n    def sample_v(self, y):\n        wy = torch.mm(y, self.W)\n        activation = wy + self.b.expand_as(wy)\n        p_v_given_h = torch.sigmoid(activation) # p(v|h)\n        return p_v_given_h, torch.bernoulli(p_v_given_h) \n    \n    def train(self, v0, vk, ph0, phk): #contrastive divergence\n        self.W += (torch.mm(v0.t(), ph0) - torch.mm(vk.t(), phk)).t()\n        self.b += torch.sum((v0 - vk), 0)\n        self.a += torch.sum((ph0 - phk), 0)","execution_count":16,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nv = len(training_set[0]) #number of features/variables of training_set (in this case, number of movies)\nnh = 100 # number of hidden nodes (selected by us; in this case number of different features of various movies)\nbatch_size = 100\nrbm = RBM(nv, nh)","execution_count":17,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Training RBM"},{"metadata":{"trusted":true},"cell_type":"code","source":"nb_epoch = 10\n\nfor epoch in range(1, nb_epoch + 1):\n    train_loss = 0\n    s = 0.\n    for id_user in range(0, nb_users - batch_size, batch_size): #id_user of first user in each batch\n        vk = training_set[id_user : id_user + batch_size] #first user ~ last user in each batch\n        v0 = training_set[id_user : id_user + batch_size]\n        ph0,_ = rbm.sample_h(v0) # ,_: if you want to return only the first element of the result\n        for k in range(10): #k steps of contrastive divergence (random walk in gibbs sampling, MCMC technique)\n            _,hk = rbm.sample_h(vk)\n            _,vk = rbm.sample_v(hk) #update vk\n            vk[v0<0] = v0[v0<0] #excluding rating-1 in gibbs sampling (which we assigned as -1 whenever a movie was not watched by user before)\n            # so making sure training doesn't happen on movies that are unwatched and thus don't have available rating before\n\n        phk,_ = rbm.sample_h(vk)\n        rbm.train(v0, vk, ph0, phk)\n\n        train_loss += torch.mean(torch.abs(v0[v0 >= 0] - vk[v0 >= 0])) \n        # Can use many metrics for evaluation like simple distance, RMSE etc. but for this RBM example, \n        # we will use \"simple absolute distance\" between predicted rating and actual rating\n        s += 1.\n    print('epoch: '+str(epoch)+' loss: '+str(train_loss/s))\n","execution_count":18,"outputs":[{"output_type":"stream","text":"epoch: 1 loss: tensor(0.3509)\nepoch: 2 loss: tensor(0.2391)\nepoch: 3 loss: tensor(0.2506)\nepoch: 4 loss: tensor(0.2485)\nepoch: 5 loss: tensor(0.2479)\nepoch: 6 loss: tensor(0.2495)\nepoch: 7 loss: tensor(0.2485)\nepoch: 8 loss: tensor(0.2486)\nepoch: 9 loss: tensor(0.2500)\nepoch: 10 loss: tensor(0.2476)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ############# Using RMSE as metric for training ############\n\n# nb_epoch = 10\n# for epoch in range(1, nb_epoch + 1):\n#     train_loss = 0\n#     s = 0.\n#     for id_user in range(0, nb_users - batch_size, batch_size):\n#         vk = training_set[id_user:id_user+batch_size]\n#         v0 = training_set[id_user:id_user+batch_size]\n#         ph0,_ = rbm.sample_h(v0)\n#         for k in range(10):\n#             _,hk = rbm.sample_h(vk)\n#             _,vk = rbm.sample_v(hk)\n#             vk[v0<0] = v0[v0<0]\n#         phk,_ = rbm.sample_h(vk)\n#         rbm.train(v0, vk, ph0, phk)\n#         train_loss += np.sqrt(torch.mean((v0[v0>=0] - vk[v0>=0])**2)) # RMSE here\n#         s += 1.\n#     print('epoch: '+str(epoch)+' loss: '+str(train_loss/s))","execution_count":20,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Testing RBM"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_loss = 0\ns = 0.\nfor id_user in range(nb_users):\n    v = training_set[id_user:id_user+1]\n    vt = test_set[id_user:id_user+1]\n    if len(vt[vt>=0]) > 0:\n        _,h = rbm.sample_h(v)\n        _,v = rbm.sample_v(h)\n        test_loss += torch.mean(torch.abs(vt[vt>=0] - v[vt>=0]))\n        s += 1.\nprint('test loss: '+str(test_loss/s))","execution_count":19,"outputs":[{"output_type":"stream","text":"test loss: tensor(0.2434)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ####### using RMSE for evaluating on test set #########3\n# test_loss = 0\n# s = 0.\n# for id_user in range(nb_users):\n#     v = training_set[id_user:id_user+1]\n#     vt = test_set[id_user:id_user+1]\n#     if len(vt[vt>=0]) > 0:\n#         _,h = rbm.sample_h(v)\n#         _,v = rbm.sample_v(h)\n#         test_loss += np.sqrt(torch.mean((vt[vt>=0] - v[vt>=0])**2)) # RMSE here\n#         s += 1.\n# print('test loss: '+str(test_loss/s))","execution_count":21,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}